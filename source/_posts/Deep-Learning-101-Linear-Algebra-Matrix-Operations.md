---
title: 矩阵的基本操作
date: 2018-12-11 16:05:06
categories: [深度学习,线性代数]
mathjax: true
---

本文简单介绍了深度学习中用到的矩阵的基本操作，包括转置，矩阵与标量、向量、矩阵的加法和乘法。

<!-- more -->

### 转置 （Transpose）
首先需要定义**主对角线（Main Diagonal）**的概念。所谓主对角线，即从矩阵的左上到右下的一条45度的对角线。而转置，即是以主对角线为轴，将矩阵做一个镜像变换。这个操作记做 $A^\top$ 。直观理解，就是行变成列，列变成行。

$$(A^\top)_{i,j}=A_{j, i}$$

### 加法
当两个矩阵的大小一样时（即行列数均相等），我们可以将矩阵进行直接加法运算。
$$C = A + B, 其中 C_{i,j}=A_{i,j} + B_{i,j} $$

矩阵与标量的加法，即矩阵的每个元素均与标量相加。
$$B = A + b, 其中 B_{i,j}=A_{i,j} + b$$

矩阵与向量的加法，即矩阵的每一行均与向量相加。
$$B_{i,j}=A_{i,j} + {\bf b}_j$$

### 乘法 (重要)
矩阵与标量的乘法，即用矩阵中的每个元素乘以标量。
$$B = A \times b, 其中 B_{i,j}=A_{i,j} \times b$$

矩阵与矩阵的乘法并不适用于任意两个矩阵，为了使乘法可以被定义，约定 $$A$$ 的列数必须与 $$B$$ 的行数相等。即形如 $$A_{m \times n}$$ 和 $$B_{n \times p}$$ 的两个矩阵是可以相乘的，结果是一个 $$n \times p$$ 的矩阵。矩阵乘法的数学定义是
$$C_{i,j} = \sum_{k}A_{i,k}B_{k,j}$$

矩阵的乘法满足分配律和结合律，但是不满足交换律（从定义可以简单推出）。

矩阵的乘法可以理解为，结果矩阵的元素 $$C_{i,j}$$ 是 $$A_{i:}$$（第$$i$$行） 和 $$B_{:j}$$ （第$$j$$列）的点积 (dot product)。两个向量的点积即对应元素的乘积之和。向量的点积（$${\bf a \times b}$$）可以看作是矩阵乘积 $${\bf a^\top b}$$（点积的计算是满足交换律的）。

矩阵乘积的转置定义如下
$$(AB)^\top=B^\top A^\top$$

矩阵与向量的乘积，可以看作是 $$m\times n$$的矩阵 $$A_{m\times n}$$ 与一个 $$x_{n\times 1}$$的矩阵的乘积，我们把这个操作写作$${\bf Ax=b}$$，其中$$A$$为已知矩阵，$$\bf b$$为已知的$$m$$维向量(即$$m\times 1$$矩阵)，$$x_{n\times1}$$为未知向量。